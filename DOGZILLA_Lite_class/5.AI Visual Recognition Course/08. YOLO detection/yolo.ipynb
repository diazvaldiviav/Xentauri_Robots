{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@Copyright (C): 2015-2024, Shenzhen Yahboom Tech\n",
    "@Author: clhchan \n",
    "@Date: 2024-07-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库 Importing libraries\n",
    "#导入xgoedu\n",
    "from xgoedu import XGOEDU \n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os,sys,time,json,base64\n",
    "import spidev as SPI\n",
    "import xgoscreen.LCD_2inch as LCD_2inch\n",
    "import RPi.GPIO as GPIO\n",
    "from PIL import Image,ImageDraw,ImageFont\n",
    "import json\n",
    "import threading\n",
    "\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "#显示摄像头组件 Display camera components\n",
    "image_widget = widgets.Image(format='jpeg', width=320, height=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bgr8转jpeg格式  bgr8 to jpeg format\n",
    "import enum\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yoloXgo():\n",
    "    def __init__(self,model,classes,inputwh,thresh):\n",
    "        import onnxruntime \n",
    "        self.session = onnxruntime.InferenceSession(model)\n",
    "        self.input_width=inputwh[0]\n",
    "        self.input_height=inputwh[1]\n",
    "        self.thresh=thresh\n",
    "        self.classes=classes\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "\n",
    "    # tanh函数\n",
    "    def tanh(self,x):\n",
    "        return 2. / (1 + np.exp(-2 * x)) - 1\n",
    "\n",
    "    # 数据预处理\n",
    "    def preprocess(self,src_img, size):\n",
    "        output = cv2.resize(src_img,(size[0], size[1]),interpolation=cv2.INTER_AREA)\n",
    "        output = output.transpose(2,0,1)\n",
    "        output = output.reshape((1, 3, size[1], size[0])) / 255\n",
    "        return output.astype('float32') \n",
    "\n",
    "    # nms算法\n",
    "    def nms(self,dets,thresh=0.45):\n",
    "        # dets:N*M,N是bbox的个数，M的前4位是对应的（x1,y1,x2,y2），第5位是对应的分数\n",
    "        # #thresh:0.3,0.5....\n",
    "        x1 = dets[:, 0]\n",
    "        y1 = dets[:, 1]\n",
    "        x2 = dets[:, 2]\n",
    "        y2 = dets[:, 3]\n",
    "        scores = dets[:, 4]\n",
    "        areas = (x2 - x1 + 1) * (y2 - y1 + 1)  # 求每个bbox的面积\n",
    "        order = scores.argsort()[::-1]  # 对分数进行倒排序\n",
    "        keep = []  # 用来保存最后留下来的bboxx下标\n",
    "\n",
    "        while order.size > 0:\n",
    "            i = order[0]  # 无条件保留每次迭代中置信度最高的bbox\n",
    "            keep.append(i)\n",
    "\n",
    "            # 计算置信度最高的bbox和其他剩下bbox之间的交叉区域\n",
    "            xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "            yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "            xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "            yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "            # 计算置信度高的bbox和其他剩下bbox之间交叉区域的面积\n",
    "            w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "            h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "            inter = w * h\n",
    "\n",
    "            # 求交叉区域的面积占两者（置信度高的bbox和其他bbox）面积和的必烈\n",
    "            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "            # 保留ovr小于thresh的bbox，进入下一次迭代。\n",
    "            inds = np.where(ovr <= thresh)[0]\n",
    "\n",
    "            # 因为ovr中的索引不包括order[0]所以要向后移动一位\n",
    "            order = order[inds + 1]\n",
    "        \n",
    "        output = []\n",
    "        for i in keep:\n",
    "            output.append(dets[i].tolist())\n",
    "\n",
    "        return output\n",
    "\n",
    "    def run(self, img,):\n",
    "        pred = []\n",
    "\n",
    "        # 输入图像的原始宽高\n",
    "        H, W, _ = img.shape\n",
    "\n",
    "        # 数据预处理: resize, 1/255\n",
    "        data = self.preprocess(img, [self.input_width, self.input_height])\n",
    "\n",
    "        # 模型推理\n",
    "        input_name = self.session.get_inputs()[0].name\n",
    "        feature_map = self.session.run([], {input_name: data})[0][0]\n",
    "\n",
    "        # 输出特征图转置: CHW, HWC\n",
    "        feature_map = feature_map.transpose(1, 2, 0)\n",
    "        # 输出特征图的宽高\n",
    "        feature_map_height = feature_map.shape[0]\n",
    "        feature_map_width = feature_map.shape[1]\n",
    "\n",
    "        # 特征图后处理\n",
    "        for h in range(feature_map_height):\n",
    "            for w in range(feature_map_width):\n",
    "                data = feature_map[h][w]\n",
    "\n",
    "                # 解析检测框置信度\n",
    "                obj_score, cls_score = data[0], data[5:].max()\n",
    "                score = (obj_score ** 0.6) * (cls_score ** 0.4)\n",
    "\n",
    "                # 阈值筛选\n",
    "                if score > self.thresh:\n",
    "                    # 检测框类别\n",
    "                    cls_index = np.argmax(data[5:])\n",
    "                    # 检测框中心点偏移\n",
    "                    x_offset, y_offset = self.tanh(data[1]), self.tanh(data[2])\n",
    "                    # 检测框归一化后的宽高\n",
    "                    box_width, box_height = self.sigmoid(data[3]), self.sigmoid(data[4])\n",
    "                    # 检测框归一化后中心点\n",
    "                    box_cx = (w + x_offset) / feature_map_width\n",
    "                    box_cy = (h + y_offset) / feature_map_height\n",
    "                    \n",
    "                    # cx,cy,w,h => x1, y1, x2, y2\n",
    "                    x1, y1 = box_cx - 0.5 * box_width, box_cy - 0.5 * box_height\n",
    "                    x2, y2 = box_cx + 0.5 * box_width, box_cy + 0.5 * box_height\n",
    "                    x1, y1, x2, y2 = int(x1 * W), int(y1 * H), int(x2 * W), int(y2 * H)\n",
    "\n",
    "                    pred.append([x1, y1, x2, y2, score, cls_index])\n",
    "        datas=np.array(pred)\n",
    "        data=[]\n",
    "        if len(datas)>0:\n",
    "            boxes=self.nms(datas)\n",
    "            for b in boxes:\n",
    "                obj_score, cls_index = b[4], int(b[5])\n",
    "                x1, y1, x2, y2 = int(b[0]), int(b[1]), int(b[2]), int(b[3])\n",
    "                s={'classes':self.classes[cls_index],'score':'%.2f' % obj_score,'xywh':[x1,y1,x2-x1,y2-y1],}\n",
    "                data.append(s)\n",
    "            return data\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c84307dba1443ef8c306e7b1311477a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='240', width='320')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "('person', (-16, 29))\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "('person', (26, -1))\n",
      "('person', (18, 1))\n",
      "('person', (2, -1))\n",
      "None\n",
      "('person', (-1, 7))\n",
      "('bottle', (234, 109))\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "('bottle', (232, 115))\n",
      "None\n",
      "('tvmonitor', (159, -2))\n",
      "None\n",
      "None\n",
      "('tvmonitor', (102, -4))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -2))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -2))\n",
      "('tvmonitor', (101, -2))\n",
      "None\n",
      "('tvmonitor', (102, -3))\n",
      "('tvmonitor', (101, -2))\n",
      "('tvmonitor', (101, -4))\n",
      "('tvmonitor', (101, -3))\n",
      "None\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -2))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -2))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (102, -3))\n",
      "('tvmonitor', (101, -4))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (102, -3))\n",
      "('tvmonitor', (101, -3))\n",
      "('tvmonitor', (101, -2))\n",
      "None\n",
      "None\n",
      "('tvmonitor', (102, -3))\n",
      "('tvmonitor', (102, -3))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m#循环进行摄像头识别，按c键退出\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     result\u001b[38;5;241m=\u001b[39m\u001b[43mmy_edu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myoloFast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#缺省参数，默认使用摄像头识别\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m, in \u001b[0;36mmy_yolo.yoloFast\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     image\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(target))\n\u001b[0;32m---> 47\u001b[0m datas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myolo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m b,g,r \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39msplit(image)\n\u001b[1;32m     49\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mmerge((r,g,b))\n",
      "Cell \u001b[0;32mIn[3], line 78\u001b[0m, in \u001b[0;36myoloXgo.run\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# 模型推理\u001b[39;00m\n\u001b[1;32m     77\u001b[0m input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mget_inputs()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m---> 78\u001b[0m feature_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# 输出特征图转置: CHW, HWC\u001b[39;00m\n\u001b[1;32m     81\u001b[0m feature_map \u001b[38;5;241m=\u001b[39m feature_map\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:217\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    215\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class my_yolo():\n",
    "    def __init__(self):\n",
    "        self.mydisplay = LCD_2inch.LCD_2inch()\n",
    "        self.mydisplay.Init()\n",
    "        self.mydisplay.clear()\n",
    "        self.splash = Image.new(\"RGB\",(320,240),\"black\")\n",
    "        self.mydisplay.ShowImage(self.splash)\n",
    "        self.draw = ImageDraw.Draw(self.splash)\n",
    "        self.font = ImageFont.truetype(\"/home/pi/model/msyh.ttc\",15)\n",
    "        self.key1=17\n",
    "        self.key2=22\n",
    "        self.key3=23\n",
    "        self.key4=24\n",
    "        self.cap=None\n",
    "        self.hand=None\n",
    "        self.yolo=None\n",
    "        self.face=None\n",
    "        self.face_classifier=None\n",
    "        self.classifier=None\n",
    "        self.agesexmark=None\n",
    "        self.camera_still=False\n",
    "        GPIO.setup(self.key1,GPIO.IN,GPIO.PUD_UP)\n",
    "        GPIO.setup(self.key2,GPIO.IN,GPIO.PUD_UP)\n",
    "        GPIO.setup(self.key3,GPIO.IN,GPIO.PUD_UP)\n",
    "        GPIO.setup(self.key4,GPIO.IN,GPIO.PUD_UP)\n",
    "\n",
    "    def open_camera(self):\n",
    "        if self.cap==None:\n",
    "            self.cap =cv2.VideoCapture(0)\n",
    "            self.cap.set(3,320)\n",
    "            self.cap.set(4,240)\n",
    "    def close_camera(self):\n",
    "        self.cap.release() \n",
    "        \n",
    "    def yoloFast(self,target=\"camera\"):\n",
    "        ret=''\n",
    "        self.open_camera()\n",
    "        if self.yolo==None:\n",
    "            self.yolo = yoloXgo('/home/pi/model/Model.onnx',\n",
    "            ['person','bicycle','car','motorbike','aeroplane','bus','train','truck','boat','traffic light','fire hydrant','stop sign','parking meter','bench','bird','cat','dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack','umbrella','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball','kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket','bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple','sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair','sofa','pottedplant','bed','diningtable','toilet','tvmonitor','laptop','mouse','remote','keyboard','cell phone','microwave','oven','toaster','sink','refrigerator','book','clock','vase','scissors','teddy bear','hair drier','toothbrush'],\n",
    "            [352,352],0.66)\n",
    "        if target==\"camera\":\n",
    "            self.open_camera()\n",
    "            success,image = self.cap.read()\n",
    "        else:\n",
    "            image=np.array(Image.open(target))\n",
    "        datas = self.yolo.run(image)\n",
    "        b,g,r = cv2.split(image)\n",
    "        image = cv2.merge((r,g,b))\n",
    "        image = cv2.flip(image,1)\n",
    "        if datas:\n",
    "            for data in datas:\n",
    "                XGOEDU.rectangle(self,image,data['xywh'],\"#33cc00\",2)\n",
    "                xy= (data['xywh'][0], data['xywh'][1])\n",
    "                XGOEDU.text(self,image,data['classes'],xy,1,\"#ff0000\",2)\n",
    "                value_yolo = data['classes']\n",
    "                ret=(value_yolo,xy)\n",
    "        imgok = Image.fromarray(image)\n",
    "\n",
    "        #把颜色转回来\n",
    "        r,g,b = cv2.split(image)\n",
    "        image1 = cv2.merge((b,g,r))\n",
    "        #cv2.imshow('frame', image1)\n",
    "        image_widget.value = bgr8_to_jpeg(image1)\n",
    "        #显示在终端上\n",
    "        \n",
    "        self.mydisplay.ShowImage(imgok)\n",
    "        if ret=='':\n",
    "            return None\n",
    "        else:\n",
    "            return ret\n",
    "\n",
    "display(image_widget)\n",
    "my_edu = my_yolo()\n",
    "#循环进行摄像头识别，按c键退出\n",
    "while True:\n",
    "    result=my_edu.yoloFast()  #缺省参数，默认使用摄像头识别\n",
    "    print(result)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_edu.close_camera()\n",
    "del my_edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "75e9df7e176b8fac597ec9907fd9d8af994374620e1bb86231401b54ec4688aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
