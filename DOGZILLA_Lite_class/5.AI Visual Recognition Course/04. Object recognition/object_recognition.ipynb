{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@Copyright (C): 2015-2024, Shenzhen Yahboom Tech\n",
    "@Author: clhchan \n",
    "@Date: 2024-07-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os,time\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_utils\n",
    "import ipywidgets.widgets as widgets\n",
    "from image_fun import bgr8_to_jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,socket,sys,time\n",
    "import spidev as SPI\n",
    "import xgoscreen.LCD_2inch as LCD_2inch\n",
    "from PIL import Image,ImageDraw,ImageFont\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from numpy import linalg\n",
    "from xgolib import XGO\n",
    "\n",
    "g_dog = XGO(port='/dev/ttyAMA0',version=\"xgolite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#屏幕清除\n",
    "mydisplay = LCD_2inch.LCD_2inch()\n",
    "mydisplay.clear()\n",
    "splash = Image.new(\"RGB\", (mydisplay.height, mydisplay.width ),\"black\")\n",
    "mydisplay.ShowImage(splash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init camera \n",
    "cap = cv2.VideoCapture(0)  # 定义摄像头对象，参数0表示第一个摄像头 Define the camera object, parameter 0 represents the first camera\n",
    "cap.set(3, 320) # set Width\n",
    "cap.set(4, 240) # set Height\n",
    "cap.set(5, 30)  #设置帧率 Setting the frame rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpg', width=320, height=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init tf model\n",
    "\n",
    "MODEL_NAME = 'ssdlite_mobilenet_v2_coco_2018_05_09' #fast\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb' \n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt') \n",
    "NUM_CLASSES = 90 \n",
    "IMAGE_SIZE = (12, 8) \n",
    "fileAlreadyExists = os.path.isfile(PATH_TO_CKPT) \n",
    "\n",
    "if not fileAlreadyExists:\n",
    "    print('Model does not exsist !')\n",
    "    exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n",
      "Finish Load Graph..\n"
     ]
    }
   ],
   "source": [
    "# LOAD GRAPH\n",
    "print('Loading...')\n",
    "detection_graph = tf.Graph() \n",
    "with detection_graph.as_default(): \n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid: \n",
    "        serialized_graph = fid.read() \n",
    "        od_graph_def.ParseFromString(serialized_graph) \n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True) \n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print('Finish Load Graph..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(category_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict['Name']:  person\n"
     ]
    }
   ],
   "source": [
    "print(\"dict['Name']: \", category_index[1]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121411b80fd94081abb867db4b552dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpg', height='240', width='320')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 14:49:58.849112: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8640000 exceeds 10% of free system memory.\n",
      "2025-05-15 14:49:59.375164: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8640000 exceeds 10% of free system memory.\n",
      "2025-05-15 14:49:59.778133: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8640000 exceeds 10% of free system memory.\n",
      "2025-05-15 14:50:00.169222: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8640000 exceeds 10% of free system memory.\n",
      "2025-05-15 14:50:00.537323: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8640000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "truck\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "couch\n",
      "couch\n",
      "couch\n",
      "couch\n",
      "couch\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "microwave\n",
      "microwave\n",
      "microwave\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "person\n",
      "couch\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "person\n",
      "couch\n",
      "tv\n",
      "person\n",
      "couch\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "couch\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "car\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "person\n",
      "tv\n",
      "tv\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "car\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "person\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "tv\n",
      "couch\n",
      "person\n",
      "tv\n",
      "tv\n",
      "couch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m             num_detections \u001b[38;5;241m=\u001b[39m detection_graph\u001b[38;5;241m.\u001b[39mget_tensor_by_name(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_detections:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#             print('Running detection..') \u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m             (boxes, scores, classes, num) \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdetection_boxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetection_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetection_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_detections\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mimage_tensor\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_np_expanded\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#             print('Done.  Visualizing..')\u001b[39;00m\n\u001b[1;32m     23\u001b[0m             vis_utils\u001b[38;5;241m.\u001b[39mvisualize_boxes_and_labels_on_image_array(\n\u001b[1;32m     24\u001b[0m                     frame,\n\u001b[1;32m     25\u001b[0m                     np\u001b[38;5;241m.\u001b[39msqueeze(boxes),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m                     use_normalized_coordinates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     30\u001b[0m                     line_thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1377\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1380\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1359\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main\n",
    "t_start = time.time()\n",
    "fps = 0\n",
    "display(image_widget)\n",
    "with detection_graph.as_default():\n",
    "    with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            ##############\n",
    "            image_np_expanded = np.expand_dims(frame, axis=0) \n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0') \n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0') \n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0') \n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0') \n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "#             print('Running detection..') \n",
    "            (boxes, scores, classes, num) = sess.run( \n",
    "                [detection_boxes, detection_scores, detection_classes, num_detections], \n",
    "                feed_dict={image_tensor: image_np_expanded}) \n",
    "\n",
    "#             print('Done.  Visualizing..')\n",
    "            vis_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                    frame,\n",
    "                    np.squeeze(boxes),\n",
    "                    np.squeeze(classes).astype(np.int32),\n",
    "                    np.squeeze(scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=8)\n",
    "\n",
    "            for i in range(0, 10):\n",
    "                if scores[0][i] >= 0.5:\n",
    "                    print(category_index[int(classes[0][i])]['name'])\n",
    "                    objtype_str=category_index[int(classes[0][i])]['name']\n",
    "            ##############\n",
    "            fps = fps + 1\n",
    "            mfps = fps / (time.time() - t_start)\n",
    "            cv2.putText(frame, \"FPS:\" + str(int(mfps)), (10,25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "            image_widget.value = bgr8_to_jpeg(frame)\n",
    "\n",
    "            #显示在小车的lcd屏幕上\n",
    "            b,g,r = cv2.split(frame)\n",
    "            img = cv2.merge((r,g,b))\n",
    "            imgok = Image.fromarray(img)\n",
    "            mydisplay.ShowImage(imgok)\n",
    "\n",
    "            # k = cv2.waitKey(1) & 0xff\n",
    "            # if k == 27:# press 'ESC' to quit\n",
    "            #     cap.release()\n",
    "            #     break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "\n",
    "mydisplay.clear()\n",
    "splash = Image.new(\"RGB\", (mydisplay.height, mydisplay.width ),\"black\")\n",
    "mydisplay.ShowImage(splash)\n",
    "\n",
    "del g_dog\n",
    "\n",
    "#最后需要释放掉摄像头的占用 Finally, you need to release the camera's occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "75e9df7e176b8fac597ec9907fd9d8af994374620e1bb86231401b54ec4688aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
